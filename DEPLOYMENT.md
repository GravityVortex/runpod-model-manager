# RunPod éƒ¨ç½²æŒ‡å—

## ğŸ¯ éƒ¨ç½²é€»è¾‘è¯´æ˜

è¿™ä¸ªé¡¹ç›®çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**ä½¿ç”¨ä¸€ä¸ªä¸´æ—¶ Pod ä¸‹è½½æ‰€æœ‰æ¨¡å‹åˆ° Volumeï¼Œç„¶ååœ¨å…¶ä»–é¡¹ç›® Pod ä¸­å…±äº«ä½¿ç”¨è¿™äº›æ¨¡å‹**ã€‚

### å·¥ä½œæµç¨‹

```
1. åˆ›å»º Volumeï¼ˆæŒä¹…å­˜å‚¨ï¼‰
   â†“
2. å¯åŠ¨ä¸´æ—¶ä¸‹è½½ Podï¼ˆæŒ‚è½½ Volumeï¼‰
   â†“
3. è¿è¡Œ download_models.py ä¸‹è½½æ‰€æœ‰æ¨¡å‹åˆ° Volume
   â†“
4. åˆ é™¤ä¸‹è½½ Podï¼ˆèŠ‚çœæˆæœ¬ï¼‰
   â†“
5. åœ¨å®é™…é¡¹ç›® Pod ä¸­æŒ‚è½½åŒä¸€ä¸ª Volumeï¼Œç›´æ¥ä½¿ç”¨æ¨¡å‹
```

**ä¼˜åŠ¿**ï¼š
- âœ… æ¨¡å‹åªéœ€ä¸‹è½½ä¸€æ¬¡ï¼Œå¤šä¸ªé¡¹ç›®å…±äº«
- âœ… Pod åˆ é™¤åæ¨¡å‹ä¸ä¼šä¸¢å¤±
- âœ… èŠ‚çœå­˜å‚¨ç©ºé—´å’Œä¸‹è½½æ—¶é—´
- âœ… é™ä½æˆæœ¬ï¼ˆä¸éœ€è¦æ¯ä¸ª Pod éƒ½ä¸‹è½½ï¼‰

---

## ğŸ“‹ è¯¦ç»†éƒ¨ç½²æ­¥éª¤

### æ­¥éª¤ 1: åˆ›å»º Network Volumeï¼ˆå¿…é¡»ï¼‰

1. ç™»å½• RunPod æ§åˆ¶å°ï¼šhttps://www.runpod.io/console/pods

2. è¿›å…¥ **Storage** é¡µé¢

3. ç‚¹å‡» **+ Network Volume**

4. é…ç½® Volumeï¼š
   ```
   Name: model-storageï¼ˆæˆ–ä½ å–œæ¬¢çš„åå­—ï¼‰
   Size: 50GB - 500GBï¼ˆæ ¹æ®ä½ çš„æ¨¡å‹æ•°é‡ï¼‰
   Region: é€‰æ‹©ä½ å¸¸ç”¨çš„åŒºåŸŸï¼ˆæ¯”å¦‚ US-TX-2ï¼‰
   ```

5. ç‚¹å‡» **Create** åˆ›å»º Volume

**âš ï¸ é‡è¦**ï¼š
- Volume æ˜¯æŒ‰ GB/å°æ—¶æ”¶è´¹çš„æŒä¹…å­˜å‚¨
- åˆ›å»ºåä¼šä¸€ç›´æ”¶è´¹ï¼Œç›´åˆ°åˆ é™¤
- å»ºè®®æ ¹æ®å®é™…éœ€è¦çš„æ¨¡å‹å¤§å°é€‰æ‹©å®¹é‡

---

### æ­¥éª¤ 2: å¯åŠ¨ä¸‹è½½ Pod

1. å›åˆ° **Pods** é¡µé¢

2. ç‚¹å‡» **+ GPU Pod** æˆ– **+ CPU Pod**

3. é…ç½® Podï¼š

   **GPU/Instance é€‰æ‹©**ï¼š
   ```
   - é€‰æ‹©æœ€ä¾¿å®œçš„å³å¯ï¼ˆåªæ˜¯ä¸‹è½½ï¼Œä¸éœ€è¦å¼ºå¤§ GPUï¼‰
   - æ¨èï¼šRTX A4000 æˆ–æ›´ä¾¿å®œçš„
   - æˆ–è€…é€‰æ‹© CPU Podï¼ˆæ›´ä¾¿å®œï¼‰
   ```

   **Docker Image**ï¼š
   ```
   runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel-ubuntu22.04
   æˆ–
   pytorch/pytorch:2.4.1-cuda12.1-cudnn9-runtime
   ```

   **Volume Mount**ï¼ˆå…³é”®ï¼ï¼‰ï¼š
   ```
   âœ… Attach Network Volume
   é€‰æ‹©åˆšæ‰åˆ›å»ºçš„ Volume: model-storage
   Mount Path: /workspace
   ```

   **Expose Ports**ï¼šä¸éœ€è¦

4. ç‚¹å‡» **Deploy On-Demand** æˆ– **Deploy Spot**ï¼ˆSpot æ›´ä¾¿å®œï¼‰

---

### æ­¥éª¤ 3: åœ¨ Pod ä¸­ä¸‹è½½æ¨¡å‹

1. ç­‰å¾… Pod å¯åŠ¨å®Œæˆ

2. ç‚¹å‡» **Connect** â†’ **Start Web Terminal** æˆ–ä½¿ç”¨ SSH

3. åœ¨ç»ˆç«¯æ‰§è¡Œï¼š

```bash
# 1. å…‹éš†é¡¹ç›®
cd /workspace
git clone https://github.com/GravityVortex/runpod-model-manager.git
cd runpod-model-manager

# 2. å®‰è£…ä¾èµ–ï¼ˆå¦‚æœé•œåƒä¸­æ²¡æœ‰ï¼‰
pip install modelscope huggingface-hub -i https://pypi.tuna.tsinghua.edu.cn/simple

# 3. æŸ¥çœ‹è¦ä¸‹è½½çš„é¡¹ç›®
python -m projects.loader

# 4. å¼€å§‹ä¸‹è½½æ‰€æœ‰é¡¹ç›®çš„æ¨¡å‹
python download_models.py --all

# ä¸‹è½½å®Œæˆåä¼šæ˜¾ç¤ºï¼š
# âœ… æˆåŠŸ: X/X
# ğŸ’¾ å­˜å‚¨ä½ç½®: /workspace/models
```

**ä¸‹è½½æ—¶é—´**ï¼šæ ¹æ®æ¨¡å‹å¤§å°å’Œç½‘ç»œé€Ÿåº¦ï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿåˆ°å‡ å°æ—¶ã€‚

---

### æ­¥éª¤ 4: éªŒè¯æ¨¡å‹å·²ä¸‹è½½

```bash
# æŸ¥çœ‹ä¸‹è½½çš„æ¨¡å‹
ls -lh /workspace/models/

# æŸ¥çœ‹ç£ç›˜ä½¿ç”¨
du -sh /workspace/models/
```

åº”è¯¥èƒ½çœ‹åˆ°ç±»ä¼¼ï¼š

```
/workspace/models/
â”œâ”€â”€ hub/
â”‚   â”œâ”€â”€ damo/
â”‚   â”‚   â”œâ”€â”€ speech_fsmn_vad_zh-cn-16k-common-pytorch/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ iic/
â”‚       â””â”€â”€ ...
â””â”€â”€ models--org--name/
```

---

### æ­¥éª¤ 5: åœæ­¢/åˆ é™¤ä¸‹è½½ Pod

**æ¨¡å‹å·²ä¿å­˜åœ¨ Volume ä¸­ï¼Œå¯ä»¥å®‰å…¨åˆ é™¤ Podï¼**

1. å›åˆ° RunPod æ§åˆ¶å°
2. æ‰¾åˆ°ä¸‹è½½ Pod
3. ç‚¹å‡» **Stop** æˆ– **Terminate**

**ğŸ’° çœé’±æç¤º**ï¼š
- ä¸‹è½½å®Œæˆåç«‹å³åˆ é™¤ Podï¼Œé¿å…ç»§ç»­è®¡è´¹
- Volume ä¼šä¿ç•™æ‰€æœ‰æ¨¡å‹æ•°æ®

---

### æ­¥éª¤ 6: åœ¨å®é™…é¡¹ç›®ä¸­ä½¿ç”¨æ¨¡å‹

å½“ä½ éœ€è¦è¿è¡Œå®é™…çš„ AI é¡¹ç›®æ—¶ï¼š

1. **å¯åŠ¨æ–°çš„ Pod**ï¼š
   - é€‰æ‹©åˆé€‚çš„ GPUï¼ˆæ ¹æ®é¡¹ç›®éœ€æ±‚ï¼‰
   - Docker Imageï¼šä½ çš„é¡¹ç›®é•œåƒ
   - **æŒ‚è½½åŒä¸€ä¸ª Volume**ï¼šmodel-storage â†’ /workspace

2. **åœ¨é¡¹ç›®ä»£ç ä¸­ä½¿ç”¨æ¨¡å‹**ï¼š

```python
import os

# è®¾ç½®æ¨¡å‹ç¼“å­˜è·¯å¾„æŒ‡å‘ Volume
os.environ['MODELSCOPE_CACHE'] = '/workspace/models'
os.environ['TRANSFORMERS_CACHE'] = '/workspace/models'
os.environ['HF_HOME'] = '/workspace/models'

# ç„¶åæ­£å¸¸åŠ è½½æ¨¡å‹ï¼Œä¼šè‡ªåŠ¨ä»ç¼“å­˜è¯»å–
from modelscope.pipelines import pipeline

vad_pipeline = pipeline(
    task='voice-activity-detection',
    model='damo/speech_fsmn_vad_zh-cn-16k-common-pytorch'
)
# æ¨¡å‹ä¼šä» /workspace/models åŠ è½½ï¼Œä¸ä¼šé‡æ–°ä¸‹è½½ï¼
```

---

## ğŸ”„ æ—¥å¸¸ä½¿ç”¨æµç¨‹

### æ·»åŠ æ–°æ¨¡å‹

1. ç¼–è¾‘ `projects/` ä¸‹çš„é¡¹ç›®é…ç½®ï¼Œæ·»åŠ æ–°æ¨¡å‹
2. å¯åŠ¨ä¸´æ—¶ä¸‹è½½ Podï¼ˆæŒ‚è½½åŒä¸€ä¸ª Volumeï¼‰
3. è¿è¡Œ `python download_models.py --all`
4. åªä¼šä¸‹è½½æ–°å¢çš„æ¨¡å‹ï¼ˆå·²å­˜åœ¨çš„ä¼šè·³è¿‡ï¼‰
5. åˆ é™¤ä¸‹è½½ Pod

### å¤šä¸ªé¡¹ç›®å…±äº«æ¨¡å‹

```
Volume: model-storage
   â†“
   â”œâ”€ Pod A (è¯´è¯äººåˆ†å‰²é¡¹ç›®) â†’ è¯»å– /workspace/models
   â”œâ”€ Pod B (è¯­éŸ³è¯†åˆ«é¡¹ç›®)   â†’ è¯»å– /workspace/models  
   â””â”€ Pod C (æ–‡æœ¬ç”Ÿæˆé¡¹ç›®)   â†’ è¯»å– /workspace/models
```

æ‰€æœ‰ Pod éƒ½æŒ‚è½½åŒä¸€ä¸ª Volumeï¼Œå…±äº«æ¨¡å‹ï¼ŒèŠ‚çœç©ºé—´å’Œæˆæœ¬ã€‚

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. Volume å¤§å°è§„åˆ’

| åœºæ™¯ | æ¨èå¤§å° | è¯´æ˜ |
|------|---------|------|
| å°å‹é¡¹ç›®ï¼ˆ1-5ä¸ªæ¨¡å‹ï¼‰ | 50GB | åŸºç¡€æ¨¡å‹ |
| ä¸­å‹é¡¹ç›®ï¼ˆ5-10ä¸ªæ¨¡å‹ï¼‰ | 100GB | å¤šä¸ªä¸­ç­‰æ¨¡å‹ |
| å¤§å‹é¡¹ç›®ï¼ˆLLM ç­‰ï¼‰ | 200GB+ | å¤§è¯­è¨€æ¨¡å‹ |

**è®¡ç®—æ–¹æ³•**ï¼š
```
æ€»å®¹é‡ = Î£(æ¯ä¸ªæ¨¡å‹å¤§å°) Ã— 1.2ï¼ˆé¢„ç•™ç©ºé—´ï¼‰
```

å¯ä»¥ç”¨ `python -m projects.loader` æŸ¥çœ‹æ‰€æœ‰æ¨¡å‹åˆ—è¡¨ï¼Œä¼°ç®—å¤§å°ã€‚

### 2. æˆæœ¬ä¼˜åŒ–

**ä¸‹è½½é˜¶æ®µ**ï¼š
- âœ… ä½¿ç”¨æœ€ä¾¿å®œçš„ GPU/CPU Pod
- âœ… é€‰æ‹© Spot Instanceï¼ˆä¾¿å®œ 70-80%ï¼‰
- âœ… ä¸‹è½½å®Œç«‹å³åˆ é™¤ Pod

**ä½¿ç”¨é˜¶æ®µ**ï¼š
- âœ… åªåœ¨éœ€è¦æ—¶å¯åŠ¨é¡¹ç›® Pod
- âœ… ç”¨å®Œå°±åœæ­¢ï¼ˆæŒ‰å°æ—¶è®¡è´¹ï¼‰
- âœ… Volume æŒ‰éœ€æ‰©å®¹ï¼ˆä¸è¦ä¸€å¼€å§‹å°±å¾ˆå¤§ï¼‰

### 3. åŒºåŸŸé€‰æ‹©

**å»ºè®®**ï¼š
- Volume å’Œ Pod å¿…é¡»åœ¨åŒä¸€åŒºåŸŸ
- é€‰æ‹©ç¦»ä½ è¿‘çš„åŒºåŸŸï¼ˆæ›´å¿«ï¼‰
- å¸¸ç”¨åŒºåŸŸï¼šUS-TX-2ï¼ˆå¾·å·ï¼‰ã€EU-SE-1ï¼ˆç‘å…¸ï¼‰

### 4. ç½‘ç»œåŠ é€Ÿ

å›½å†…ä¸‹è½½ HuggingFace æ¨¡å‹å¯èƒ½è¾ƒæ…¢ï¼Œå¯ä»¥ï¼š

```bash
# ä½¿ç”¨é•œåƒç«™ï¼ˆå¦‚æœæ”¯æŒï¼‰
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–è€…åœ¨ä»£ç ä¸­è®¾ç½®ä»£ç†
export HTTP_PROXY=http://your-proxy:port
export HTTPS_PROXY=http://your-proxy:port
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆè¦ç”¨ Volume è€Œä¸æ˜¯å®¹å™¨å­˜å‚¨ï¼Ÿ

**A**: å®¹å™¨å­˜å‚¨ä¼šåœ¨ Pod åˆ é™¤æ—¶ä¸¢å¤±ã€‚Volume æ˜¯æŒä¹…å­˜å‚¨ï¼Œæ•°æ®æ°¸ä¹…ä¿å­˜ã€‚

```
å®¹å™¨å­˜å‚¨ âŒ:
Pod å¯åŠ¨ â†’ ä¸‹è½½æ¨¡å‹ â†’ Pod åˆ é™¤ â†’ æ¨¡å‹ä¸¢å¤± â†’ ä¸‹æ¬¡åˆè¦é‡æ–°ä¸‹è½½

Volume âœ…:
Pod å¯åŠ¨ â†’ ä¸‹è½½æ¨¡å‹åˆ° Volume â†’ Pod åˆ é™¤ â†’ æ¨¡å‹ä¿ç•™ â†’ ä¸‹æ¬¡ç›´æ¥ä½¿ç”¨
```

### Q2: Volume æ”¶è´¹å—ï¼Ÿ

**A**: æ˜¯çš„ã€‚Volume æŒ‰ GB/å°æ—¶æ”¶è´¹ï¼Œå¤§çº¦ $0.10-0.15/GB/æœˆã€‚
- 50GB Volume â‰ˆ $5-7.5/æœˆ
- ä½†æ¯”æ¯æ¬¡ä¸‹è½½æ¨¡å‹èŠ‚çœçš„æ—¶é—´å’Œæµé‡è´¹ç”¨ä¾¿å®œ

### Q3: å¯ä»¥å¤šä¸ª Pod åŒæ—¶è®¿é—®åŒä¸€ä¸ª Volume å—ï¼Ÿ

**A**: å¯ä»¥ï¼RunPod Network Volume æ”¯æŒå¤šä¸ª Pod åŒæ—¶æŒ‚è½½è¯»å–ã€‚

### Q4: æ¨¡å‹ä¸‹è½½å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**: 
```bash
# 1. æ£€æŸ¥ç½‘ç»œ
ping modelscope.cn

# 2. æŸ¥çœ‹è¯¦ç»†é”™è¯¯
python download_models.py --all 2>&1 | tee download.log

# 3. é‡è¯•å•ä¸ªæ¨¡å‹
python download_models.py --source modelscope damo/speech_fsmn_vad_zh-cn-16k-common-pytorch

# 4. æ£€æŸ¥ Volume ç©ºé—´
df -h /workspace
```

### Q5: å¦‚ä½•åˆ é™¤ä¸éœ€è¦çš„æ¨¡å‹é‡Šæ”¾ç©ºé—´ï¼Ÿ

```bash
# è¿›å…¥æ¨¡å‹ç›®å½•
cd /workspace/models

# åˆ é™¤æŒ‡å®šæ¨¡å‹
rm -rf hub/damo/old-model-name/
rm -rf models--org--old-model/

# æŸ¥çœ‹é‡Šæ”¾çš„ç©ºé—´
du -sh /workspace/models/
```

---

## ğŸ“Š æˆæœ¬ä¼°ç®—ç¤ºä¾‹

**åœºæ™¯**ï¼šä¸‹è½½ 10 ä¸ªä¸­ç­‰å¤§å°æ¨¡å‹ï¼ˆå…± 50GBï¼‰

| é¡¹ç›® | é…ç½® | æ—¶é•¿ | è´¹ç”¨ |
|------|------|------|------|
| Volume | 50GB | æŒç»­ | ~$6/æœˆ |
| ä¸‹è½½ Pod | RTX A4000 Spot | 2 å°æ—¶ | ~$0.60 |
| é¡¹ç›® Pod | RTX 4090 æŒ‰éœ€ | æ¯æ¬¡ 1 å°æ—¶ | ~$0.70/æ¬¡ |

**æ€»æˆæœ¬**ï¼šVolume $6/æœˆ + ä¸‹è½½ä¸€æ¬¡æ€§ $0.60 + æŒ‰ä½¿ç”¨ä»˜è´¹

**vs ä¸ç”¨ Volume**ï¼šæ¯æ¬¡å¯åŠ¨ Pod éƒ½è¦é‡æ–°ä¸‹è½½ â†’ æµªè´¹æ—¶é—´ + å¯èƒ½çš„æµé‡è´¹

---

## ğŸš€ å¿«é€Ÿå¼€å§‹å‘½ä»¤é€ŸæŸ¥

```bash
# === é¦–æ¬¡éƒ¨ç½² ===

# 1. åœ¨ RunPod åˆ›å»º Volume: model-storage (50GB+)
# 2. åˆ›å»º Pod å¹¶æŒ‚è½½ Volume åˆ° /workspace
# 3. åœ¨ Pod Terminalï¼š

cd /workspace
git clone https://github.com/GravityVortex/runpod-model-manager.git
cd runpod-model-manager
pip install modelscope huggingface-hub
python download_models.py --all

# 4. ä¸‹è½½å®Œæˆååˆ é™¤ Podï¼ŒVolume ä¿ç•™


# === åœ¨é¡¹ç›®ä¸­ä½¿ç”¨ ===

# 1. æ–°å»ºé¡¹ç›® Podï¼ŒæŒ‚è½½åŒä¸€ä¸ª Volume
# 2. åœ¨é¡¹ç›®ä»£ç ä¸­ï¼š

import os
os.environ['MODELSCOPE_CACHE'] = '/workspace/models'
os.environ['TRANSFORMERS_CACHE'] = '/workspace/models'
os.environ['HF_HOME'] = '/workspace/models'

# ç„¶åæ­£å¸¸åŠ è½½æ¨¡å‹ï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨ç¼“å­˜
```

---

éœ€è¦æ›´å¤šå¸®åŠ©ï¼ŸæŸ¥çœ‹ [README.md](./README.md) å’Œ [ARCHITECTURE.md](./ARCHITECTURE.md)
