# -*- coding: utf-8 -*-
"""
é€šç”¨æ¨¡å‹ä¸‹è½½å·¥å…· - æ”¯æŒ ModelScope / HuggingFace ç­‰å¤šç§æº
åœ¨ RunPod Pod ä¸­è¿è¡Œï¼Œä¸‹è½½æ¨¡å‹åˆ° Volume

ä½¿ç”¨æ–¹æ³•ï¼š
  python download_models.py model1 model2 model3 ...
  python download_models.py --file models.txt
  python download_models.py --source huggingface model1 model2
"""
import os
import sys
import argparse
from pathlib import Path

# å°è¯•å¯¼å…¥ modelscopeï¼ˆå¦‚æœå¯ç”¨ï¼‰
try:
    import modelscope_patch
    from modelscope import snapshot_download as ms_download
    HAS_MODELSCOPE = True
except ImportError:
    HAS_MODELSCOPE = False

# å°è¯•å¯¼å…¥ huggingface_hubï¼ˆå¦‚æœå¯ç”¨ï¼‰
try:
    from huggingface_hub import snapshot_download as hf_download
    HAS_HUGGINGFACE = True
except ImportError:
    HAS_HUGGINGFACE = False


def download_to_volume(model_ids, source='auto'):
    """ä¸‹è½½æ¨¡å‹åˆ° Volume"""
    
    print("=" * 60)
    print("ğŸš€ é€šç”¨æ¨¡å‹ä¸‹è½½å·¥å…·")
    print("=" * 60)
    
    # æ£€æµ‹ Volume è·¯å¾„
    volume_path = None
    for path in ['/workspace', '/runpod-volume', os.environ.get('RUNPOD_VOLUME_PATH', '')]:
        if path and os.path.exists(path) and os.path.isdir(path):
            volume_path = path
            break
    
    if not volume_path:
        print("âŒ æœªæ£€æµ‹åˆ° Volumeï¼Œè¯·ç¡®ä¿åœ¨ RunPod Pod ä¸­è¿è¡Œ")
        sys.exit(1)
    
    model_cache = os.path.join(volume_path, 'models')
    Path(model_cache).mkdir(parents=True, exist_ok=True)
    
    # è®¾ç½®ç¼“å­˜è·¯å¾„
    os.environ['MODELSCOPE_CACHE'] = model_cache
    os.environ['TRANSFORMERS_CACHE'] = model_cache
    os.environ['HF_HOME'] = model_cache
    
    print(f"ğŸ“ Volume: {volume_path}")
    print(f"ğŸ“¦ æ¨¡å‹ç›®å½•: {model_cache}")
    print(f"ğŸ“Š å¾…ä¸‹è½½: {len(model_ids)} ä¸ªæ¨¡å‹\n")
    
    # ä¸‹è½½æ‰€æœ‰æ¨¡å‹
    print("=" * 60)
    print("å¼€å§‹ä¸‹è½½...")
    print("=" * 60)
    
    success = 0
    failed = []
    
    for i, model_id in enumerate(model_ids, 1):
        print(f"\n[{i}/{len(model_ids)}] {model_id}")
        
        try:
            # è‡ªåŠ¨é€‰æ‹©ä¸‹è½½æº
            if source == 'auto':
                # ç®€å•åˆ¤æ–­ï¼šå¦‚æœåŒ…å«ä¸­æ–‡ç»„ç»‡åï¼Œä¼˜å…ˆ ModelScope
                if model_id.startswith(('iic/', 'damo/', 'alibaba/')):
                    use_source = 'modelscope'
                else:
                    use_source = 'huggingface' if HAS_HUGGINGFACE else 'modelscope'
            else:
                use_source = source
            
            # æ‰§è¡Œä¸‹è½½
            if use_source == 'modelscope':
                if not HAS_MODELSCOPE:
                    print("  âŒ ModelScope æœªå®‰è£…")
                    failed.append(model_id)
                    continue
                ms_download(model_id, cache_dir=model_cache)
                print(f"  âœ… ä¸‹è½½å®Œæˆ (ModelScope)")
                
            elif use_source == 'huggingface':
                if not HAS_HUGGINGFACE:
                    print("  âŒ HuggingFace Hub æœªå®‰è£…")
                    failed.append(model_id)
                    continue
                hf_download(model_id, cache_dir=model_cache)
                print(f"  âœ… ä¸‹è½½å®Œæˆ (HuggingFace)")
            
            success += 1
            
        except Exception as e:
            print(f"  âŒ å¤±è´¥: {e}")
            failed.append(model_id)
    
    # ç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ“Š ä¸‹è½½ç»Ÿè®¡")
    print("=" * 60)
    print(f"âœ… æˆåŠŸ: {success}/{len(model_ids)}")
    if failed:
        print(f"âŒ å¤±è´¥: {len(failed)}")
        for model in failed:
            print(f"  - {model}")
    print(f"\nğŸ’¾ å­˜å‚¨ä½ç½®: {model_cache}")
    print("å¯ä»¥åˆ é™¤æ­¤ Podï¼Œæ¨¡å‹å·²ä¿å­˜åœ¨ Volume\n")


def download_from_projects():
    """ä»é¡¹ç›®é…ç½®ä¸‹è½½æ‰€æœ‰æ¨¡å‹ï¼ˆè°ƒåº¦æ¨¡å¼ï¼‰"""
    from projects.loader import ProjectLoader
    
    # æ‰“å°é¡¹ç›®æ‘˜è¦
    ProjectLoader.print_summary()
    
    # è·å–æ‰€æœ‰é¡¹ç›®
    projects = ProjectLoader.get_all_projects()
    
    if not projects:
        print("\nâŒ æœªæ‰¾åˆ°ä»»ä½•é¡¹ç›®é…ç½®")
        print("è¯·åœ¨ projects/ ç›®å½•ä¸‹æ·»åŠ é¡¹ç›®é…ç½®")
        sys.exit(1)
    
    # æ£€æµ‹ Volume è·¯å¾„
    volume_path = None
    for path in ['/workspace', '/runpod-volume', os.environ.get('RUNPOD_VOLUME_PATH', '')]:
        if path and os.path.exists(path) and os.path.isdir(path):
            volume_path = path
            break
    
    if not volume_path:
        print("\nâŒ æœªæ£€æµ‹åˆ° Volumeï¼Œè¯·ç¡®ä¿åœ¨ RunPod Pod ä¸­è¿è¡Œ")
        sys.exit(1)
    
    model_cache = os.path.join(volume_path, 'models')
    Path(model_cache).mkdir(parents=True, exist_ok=True)
    
    # è®¾ç½®ç¼“å­˜è·¯å¾„
    os.environ['MODELSCOPE_CACHE'] = model_cache
    os.environ['TRANSFORMERS_CACHE'] = model_cache
    os.environ['HF_HOME'] = model_cache
    
    print(f"\n{'='*60}")
    print("ğŸš€ å¼€å§‹ä¸‹è½½æ¨¡å‹åˆ° Volume")
    print(f"{'='*60}")
    print(f"ğŸ“ Volume: {volume_path}")
    print(f"ğŸ“¦ æ¨¡å‹ç›®å½•: {model_cache}\n")
    
    # è°ƒåº¦å„ä¸ªé¡¹ç›®è¿›è¡Œä¸‹è½½
    for project in projects:
        project.download_models(model_cache)
    
    print(f"\n{'='*60}")
    print("âœ… æ‰€æœ‰é¡¹ç›®ä¸‹è½½å®Œæˆ")
    print(f"{'='*60}")
    print(f"ğŸ’¾ å­˜å‚¨ä½ç½®: {model_cache}")
    print("å¯ä»¥åˆ é™¤æ­¤ Podï¼Œæ¨¡å‹å·²ä¿å­˜åœ¨ Volume\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='é€šç”¨æ¨¡å‹ä¸‹è½½å·¥å…·')
    parser.add_argument('--all', '-a', action='store_true', 
                        help='ä¸‹è½½æ‰€æœ‰é¡¹ç›®é…ç½®çš„æ¨¡å‹')
    parser.add_argument('models', nargs='*', help='æ¨¡å‹ ID åˆ—è¡¨ï¼ˆæ‰‹åŠ¨æŒ‡å®šï¼‰')
    parser.add_argument('--source', '-s', choices=['auto', 'modelscope', 'huggingface'], 
                        default='auto', help='ä¸‹è½½æºï¼ˆæ‰‹åŠ¨æ¨¡å¼ï¼‰')
    
    args = parser.parse_args()
    
    if args.all or not args.models:
        # ä»é¡¹ç›®é…ç½®ä¸‹è½½
        download_from_projects()
    else:
        # æ‰‹åŠ¨æŒ‡å®šæ¨¡å‹
        model_ids = list(args.models)
        download_to_volume(model_ids, source=args.source)
