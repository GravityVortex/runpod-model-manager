#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RunPod S3 ä¸Šä¼ å·¥å…·
æä¾›å¯åœ¨ä»£ç ä¸­è°ƒç”¨çš„ä¸Šä¼ æ–¹æ³•ï¼Œæ”¯æŒè¯¦ç»†æ—¥å¿—è¾“å‡º
"""
import os
import sys
import time
import hashlib
from pathlib import Path
from typing import Optional, Dict

from src.s3_config import S3Config


def _sha256_file(path: Path) -> str:
    """è®¡ç®—æ–‡ä»¶ SHA256"""
    h = hashlib.sha256()
    with path.open("rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            h.update(chunk)
    return h.hexdigest()


def _format_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.2f} PB"


def _create_s3_client(config: S3Config):
    """åˆ›å»º S3 å®¢æˆ·ç«¯"""
    try:
        import boto3
        import botocore.config
        import urllib3
    except ImportError as e:
        raise ImportError("éœ€è¦å®‰è£… boto3: pip install boto3") from e

    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    boto_config = botocore.config.Config(
        signature_version="s3v4",
        retries={"max_attempts": 3, "mode": "standard"},
    )
    return boto3.client(
        "s3",
        aws_access_key_id=config.access_key,
        aws_secret_access_key=config.secret_key,
        region_name=config.get_region(),
        endpoint_url=config.get_endpoint_url(),
        config=boto_config,
        verify=False,
    )


def _build_remote_path(models_subdir: str, remote_key: str) -> str:
    """æ„å»ºå®Œæ•´çš„è¿œç¨‹è·¯å¾„"""
    subdir = models_subdir.strip('/')
    key = remote_key.strip('/')
    if subdir:
        return f"{subdir}/{key}"
    return key


class _ProgressCallback:
    """ä¸Šä¼ è¿›åº¦å›è°ƒ"""
    def __init__(self, file_size: int, verbose: bool = True):
        self.file_size = file_size
        self.verbose = verbose
        self.uploaded = 0
        self.start_time = time.time()
        self.last_print_time = 0

    def __call__(self, bytes_amount):
        self.uploaded += bytes_amount
        if not self.verbose:
            return
        
        current_time = time.time()
        if current_time - self.last_print_time < 1.0 and self.uploaded < self.file_size:
            return
        
        self.last_print_time = current_time
        percent = (self.uploaded / self.file_size) * 100
        elapsed = current_time - self.start_time
        speed = self.uploaded / elapsed if elapsed > 0 else 0
        
        print(f"   è¿›åº¦: {percent:.1f}% ({_format_size(self.uploaded)} / {_format_size(self.file_size)}) - {_format_size(speed)}/s", flush=True)


def upload_file(
    local_path: str,
    remote_key: str = None,
    models_subdir: str = '/workspace/models',
    profile: str = 'runpods3',
    verbose: bool = True
) -> bool:
    """
    ä¸Šä¼ å•ä¸ªæ–‡ä»¶åˆ° RunPod S3

    Args:
        local_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
        remote_key: è¿œç¨‹å¯¹è±¡é”®ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨æ–‡ä»¶åï¼‰
        models_subdir: å­ç›®å½•å‰ç¼€ï¼ˆé»˜è®¤ '/workspace/models'ï¼‰
        profile: S3 é…ç½® profile
        verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—

    Returns:
        ä¸Šä¼ æ˜¯å¦æˆåŠŸ
    """
    local_file = Path(local_path).expanduser().resolve()
    
    if not local_file.exists() or not local_file.is_file():
        if verbose:
            print(f"âŒ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {local_file}")
        return False
    
    # åŠ è½½é…ç½®
    config = S3Config(profile)
    if not config.is_configured():
        if verbose:
            print("âŒ S3 æœªé…ç½®")
        return False
    
    # ç”Ÿæˆ remote_key
    if remote_key is None:
        remote_key = local_file.name
    
    # æ„å»ºå®Œæ•´è·¯å¾„
    full_remote_key = _build_remote_path(models_subdir, remote_key)
    
    if verbose:
        file_size = local_file.stat().st_size
        print(f"\nğŸ“‚ æœ¬åœ°æ–‡ä»¶: {local_file}")
        print(f"   å¤§å°: {_format_size(file_size)}")
        
        print(f"\nğŸ”§ S3 é…ç½®")
        print(f"   Endpoint: {config.get_endpoint_url()}")
        print(f"   Region: {config.get_region()}")
        print(f"   Volume: {config.volume_id}")
        
        print(f"\nğŸ“ ç›®æ ‡è·¯å¾„: {full_remote_key}")
        print(f"   å®Œæ•´ S3 è·¯å¾„: s3://{config.volume_id}/{full_remote_key}")
        
        print(f"\nğŸ“¤ å¼€å§‹ä¸Šä¼ ...")
    
    try:
        s3_client = _create_s3_client(config)
        start_time = time.time()
        
        # ä¸Šä¼ æ–‡ä»¶
        callback = _ProgressCallback(local_file.stat().st_size, verbose) if verbose else None
        s3_client.upload_file(
            str(local_file),
            config.volume_id,
            full_remote_key,
            Callback=callback
        )
        
        elapsed = time.time() - start_time
        
        if verbose:
            print(f"\nâœ… ä¸Šä¼ æˆåŠŸï¼")
            print(f"   è€—æ—¶: {elapsed:.1f} ç§’")
            if elapsed > 0:
                speed = local_file.stat().st_size / elapsed
                print(f"   å¹³å‡é€Ÿåº¦: {_format_size(speed)}/s")
        
        return True
        
    except Exception as e:
        if verbose:
            print(f"\nâŒ ä¸Šä¼ å¤±è´¥: {e}")
        return False


def upload_directory(
    local_dir: str,
    remote_prefix: str = None,
    models_subdir: str = '/workspace/models',
    include_parent_dir: bool = False,
    profile: str = 'runpods3',
    verbose: bool = True
) -> Dict[str, int]:
    """
    ä¸Šä¼ æ•´ä¸ªç›®å½•åˆ° RunPod S3

    Args:
        local_dir: æœ¬åœ°ç›®å½•è·¯å¾„
        remote_prefix: è¿œç¨‹å‰ç¼€ï¼ˆä½œä¸ºæ–‡ä»¶å¤¹åï¼‰
        models_subdir: å­ç›®å½•å‰ç¼€ï¼ˆé»˜è®¤ '/workspace/models'ï¼‰
        include_parent_dir: æ˜¯å¦åŒ…å«çˆ¶ç›®å½•åï¼ˆé»˜è®¤ Falseï¼‰
        profile: S3 é…ç½® profile
        verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—

    Returns:
        {'total': int, 'success': int, 'failed': int}
    """
    local_path = Path(local_dir).expanduser().resolve()
    
    if not local_path.exists() or not local_path.is_dir():
        if verbose:
            print(f"âŒ æœ¬åœ°ç›®å½•ä¸å­˜åœ¨: {local_path}")
        return {'total': 0, 'success': 0, 'failed': 0}
    
    # æ”¶é›†æ‰€æœ‰æ–‡ä»¶
    files = []
    for item in local_path.rglob('*'):
        if item.is_file():
            files.append(item)
    
    if not files:
        if verbose:
            print(f"âš ï¸  ç›®å½•ä¸ºç©º: {local_path}")
        return {'total': 0, 'success': 0, 'failed': 0}
    
    # è®¡ç®—æ€»å¤§å°
    total_size = sum(f.stat().st_size for f in files)
    
    if verbose:
        print(f"\nğŸ“‚ æœ¬åœ°ç›®å½•: {local_path}")
        print(f"   æ–‡ä»¶æ•°é‡: {len(files)}")
        print(f"   æ€»å¤§å°: {_format_size(total_size)}")
    
    # åŠ è½½é…ç½®
    config = S3Config(profile)
    if not config.is_configured():
        if verbose:
            print("âŒ S3 æœªé…ç½®")
        return {'total': len(files), 'success': 0, 'failed': len(files)}
    
    if verbose:
        print(f"\nğŸ”§ S3 é…ç½®")
        print(f"   Endpoint: {config.get_endpoint_url()}")
        print(f"   Volume: {config.volume_id}")
    
    # ä¸Šä¼ æ–‡ä»¶
    result = {'total': len(files), 'success': 0, 'failed': 0}
    s3_client = _create_s3_client(config)
    
    if verbose:
        print(f"\nğŸ“¤ å¼€å§‹ä¸Šä¼  {len(files)} ä¸ªæ–‡ä»¶...\n")
    
    # ä½¿ç”¨ tqdm è¿›åº¦æ¡
    try:
        from tqdm import tqdm
        use_tqdm = verbose
    except ImportError:
        use_tqdm = False
    
    iterator = tqdm(files, desc="ä¸Šä¼ è¿›åº¦", unit="file", position=0, leave=True) if use_tqdm else files
    
    for file_path in iterator:
        # è®¡ç®—ç›¸å¯¹è·¯å¾„
        rel_path = file_path.relative_to(local_path)
        
        # æ„å»ºè¿œç¨‹è·¯å¾„
        if include_parent_dir:
            parent_name = local_path.name
            if remote_prefix:
                remote_key = f"{remote_prefix}/{parent_name}/{rel_path}"
            else:
                remote_key = f"{parent_name}/{rel_path}"
        else:
            if remote_prefix:
                remote_key = f"{remote_prefix}/{rel_path}"
            else:
                remote_key = str(rel_path)
        
        full_remote_key = _build_remote_path(models_subdir, remote_key)
        
        try:
            s3_client.upload_file(
                str(file_path),
                config.volume_id,
                full_remote_key
            )
            result['success'] += 1
            if use_tqdm:
                tqdm.write(f"âœ… {file_path} â†’ s3://{config.volume_id}/{full_remote_key}")
        except Exception as e:
            result['failed'] += 1
            if use_tqdm:
                tqdm.write(f"âŒ {file_path} â†’ s3://{config.volume_id}/{full_remote_key}: {e}")
    
    if verbose:
        print(f"{'='*60}")
        print(f"ğŸ“Š ä¸Šä¼ å®Œæˆ")
        print(f"   æ€»è®¡: {result['total']} ä¸ªæ–‡ä»¶")
        print(f"   æˆåŠŸ: {result['success']} ä¸ª")
        print(f"   å¤±è´¥: {result['failed']} ä¸ª")
    
    return result
